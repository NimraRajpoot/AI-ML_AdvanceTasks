{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# AI/ML Engineering Internship \u2013 Task Reports\n", "### Tasks: 1, 2, and 5\n", "Intern Name: *[Your Name]*\n", "Date: *[Your Submission Date]*"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u2705 Task 1: News Topic Classifier Using BERT\n", "**Objective:** Fine-tune `bert-base-uncased` model on AG News dataset to classify news into categories.\n\n", "**Tools Used:** Hugging Face Transformers, Datasets, PyTorch\n\n", "**Steps:**\n", "- Loaded AG News dataset\n", "- Tokenized using BERT tokenizer\n", "- Fine-tuned `bert-base-uncased` with Trainer API\n", "- Evaluated using accuracy and F1-score\n\n", "**Results:**\n", "- Accuracy and F1-score achieved on validation subset (sample: 100 train, 50 eval)\n\n", "**Key Learnings:**\n", "- Transfer learning using BERT\n", "- Text classification with Transformers\n", "- Using Trainer API and tokenization"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u2705 Task 2: End-to-End ML Pipeline for Customer Churn\n", "**Objective:** Build a reusable ML pipeline to predict customer churn using Telco dataset.\n\n", "**Tools Used:** Scikit-learn, Pandas, Joblib\n\n", "**Steps:**\n", "- Loaded and cleaned Telco churn data\n", "- Preprocessed with `ColumnTransformer` (scaling + encoding)\n", "- Built pipeline using `Pipeline()`\n", "- Trained models: Logistic Regression & Random Forest\n", "- Used `GridSearchCV` for hyperparameter tuning\n", "- Exported final pipeline using `joblib`\n\n", "**Results:**\n", "- Achieved accuracy and F1-score using pipeline\n\n", "**Key Learnings:**\n", "- ML pipeline structuring\n", "- Feature encoding and scaling\n", "- Grid search for tuning\n", "- Exporting models for reuse"]}, {"cell_type": "markdown", "metadata": {}, "source": ["## \u2705 Task 5: Auto Tagging Support Tickets Using LLM\n", "**Objective:** Automatically classify support ticket text into tags using zero-shot classification.\n\n", "**Tools Used:** Hugging Face Transformers, `facebook/bart-large-mnli`\n\n", "**Steps:**\n", "- Loaded pre-trained model using pipeline API\n", "- Defined ticket and candidate labels (tags)\n", "- Used zero-shot classification (no training needed)\n", "- Output top 3 predicted tags with scores\n\n", "**Results:**\n", "- Tickets correctly matched to categories with high confidence\n\n", "**Key Learnings:**\n", "- Zero-shot classification\n", "- LLM-based text tagging\n", "- No-training inference via Hugging Face pipeline"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.x"}}, "nbformat": 4, "nbformat_minor": 5}